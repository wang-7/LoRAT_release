{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59da4c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5026, 52) complex128\n",
      "(5026, 52) complex128\n",
      "(5026, 52) complex128\n",
      "(5026, 52) complex64\n",
      "(5026, 52) complex64\n",
      "(5026, 52) complex64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "file_name = '/mnt/data/WQ/Raw-CSI-Data/ArgosCSI-96x8-2016-11-04-05-37-37_2.4GHz_track_left_to_right_NLOS.npy'\n",
    "file_name2 = '/mnt/data/WQ/Raw-CSI-Data/ArgosCSI-96x8-2016-05-01-06-57-58-2.4GHz-continuousmobile.npy'\n",
    "\n",
    "file_name3 = '/mnt/data/WQ/Raw-CSI-Data/ArgosCSI-96x2-2016-12-07-03-00-36_rotation_mob_horizontal_omni.npy'\n",
    "\n",
    "file_name4 = '/mnt/data/WQ/Argos/train_18_test_6_antenna_96_subcarriers_52/train/downlink/ArgosCSI-96x8-2016-05-01-07-17-44-5GHz-continuousmobility.mat'\n",
    "file_name5 = '/mnt/data/WQ/Argos/train_18_test_6_antenna_96_subcarriers_52/train/downlink/ArgosCSI-96x2-2016-12-07-03-53-37_rotation_linear_mob_patch.mat'\n",
    "\n",
    "file_name6 = '/mnt/data/WQ/Argos/train_18_test_6_antenna_96_subcarriers_52/train/downlink/ArgosCSI-96x2-2016-03-31-15-53-27_Jian_left_to_right.mat'\n",
    "\n",
    "ant_idx = 2\n",
    "data = np.load(file_name)[:5026, 0, ant_idx, :]\n",
    "data2 = np.load(file_name2)[:5026, 0, ant_idx, :]\n",
    "data3 = np.load(file_name3)[:5026, 0, ant_idx, :]\n",
    "data4 = loadmat(file_name4)['data'][:5026, 0, ant_idx, :]\n",
    "data5 = loadmat(file_name5)['data'][:5026, 0, ant_idx, :]\n",
    "data6 = loadmat(file_name6)['data'][:5026, 0, ant_idx, :]\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data2.shape, data2.dtype)\n",
    "print(data3.shape, data3.dtype)\n",
    "print(data4.shape, data4.dtype)\n",
    "print(data5.shape, data5.dtype)\n",
    "print(data6.shape, data6.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906ccada",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_env = [data, data2, data3, data5, data6]\n",
    "unknown_env = [data4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "kl_divergence_calculation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算known_env中两两之间数据的KL散度...\n",
      "data1 shape: (261352,)\n",
      "data2 shape: (261352,)\n",
      "data3 shape: (261352,)\n",
      "data4 shape: (261352,)\n",
      "data5 shape: (261352,)\n",
      "Wasserstein-1距离 between data1 and data2: 1.090226\n",
      "KL散度 between data1 and data2:\n",
      "  D_KL(P||Q) = 0.465811\n",
      "  D_KL(Q||P) = 0.528009\n",
      "  Symmetric KL = 0.496910\n",
      "  JS divergence = 0.108061\n",
      "Wasserstein-1距离 between data1 and data2: 1.090226\n",
      "\n",
      "Wasserstein-1距离 between data1 and data3: 0.726983\n",
      "KL散度 between data1 and data3:\n",
      "  D_KL(P||Q) = 0.242270\n",
      "  D_KL(Q||P) = 0.250615\n",
      "  Symmetric KL = 0.246442\n",
      "  JS divergence = 0.056328\n",
      "Wasserstein-1距离 between data1 and data3: 0.726983\n",
      "\n",
      "Wasserstein-1距离 between data1 and data4: 0.950015\n",
      "KL散度 between data1 and data4:\n",
      "  D_KL(P||Q) = 0.527138\n",
      "  D_KL(Q||P) = 0.510520\n",
      "  Symmetric KL = 0.518829\n",
      "  JS divergence = 0.115493\n",
      "Wasserstein-1距离 between data1 and data4: 0.950015\n",
      "\n",
      "Wasserstein-1距离 between data1 and data5: 0.739929\n",
      "KL散度 between data1 and data5:\n",
      "  D_KL(P||Q) = 0.147483\n",
      "  D_KL(Q||P) = 0.172578\n",
      "  Symmetric KL = 0.160031\n",
      "  JS divergence = 0.037871\n",
      "Wasserstein-1距离 between data1 and data5: 0.739929\n",
      "\n",
      "Wasserstein-1距离 between data2 and data3: 0.417780\n",
      "KL散度 between data2 and data3:\n",
      "  D_KL(P||Q) = 0.403856\n",
      "  D_KL(Q||P) = 0.391432\n",
      "  Symmetric KL = 0.397644\n",
      "  JS divergence = 0.088363\n",
      "Wasserstein-1距离 between data2 and data3: 0.417780\n",
      "\n",
      "Wasserstein-1距离 between data2 and data4: 0.154598\n",
      "KL散度 between data2 and data4:\n",
      "  D_KL(P||Q) = 0.539323\n",
      "  D_KL(Q||P) = 0.560815\n",
      "  Symmetric KL = 0.550069\n",
      "  JS divergence = 0.119295\n",
      "Wasserstein-1距离 between data2 and data4: 0.154598\n",
      "\n",
      "Wasserstein-1距离 between data2 and data5: 0.637115\n",
      "KL散度 between data2 and data5:\n",
      "  D_KL(P||Q) = 0.305786\n",
      "  D_KL(Q||P) = 0.338033\n",
      "  Symmetric KL = 0.321909\n",
      "  JS divergence = 0.074143\n",
      "Wasserstein-1距离 between data2 and data5: 0.637115\n",
      "\n",
      "Wasserstein-1距离 between data3 and data4: 0.356966\n",
      "KL散度 between data3 and data4:\n",
      "  D_KL(P||Q) = 0.543061\n",
      "  D_KL(Q||P) = 0.656376\n",
      "  Symmetric KL = 0.599719\n",
      "  JS divergence = 0.129042\n",
      "Wasserstein-1距离 between data3 and data4: 0.356966\n",
      "\n",
      "Wasserstein-1距离 between data3 and data5: 0.313289\n",
      "KL散度 between data3 and data5:\n",
      "  D_KL(P||Q) = 0.160324\n",
      "  D_KL(Q||P) = 0.200027\n",
      "  Symmetric KL = 0.180176\n",
      "  JS divergence = 0.042023\n",
      "Wasserstein-1距离 between data3 and data5: 0.313289\n",
      "\n",
      "Wasserstein-1距离 between data4 and data5: 0.623902\n",
      "KL散度 between data4 and data5:\n",
      "  D_KL(P||Q) = 0.280569\n",
      "  D_KL(Q||P) = 0.320255\n",
      "  Symmetric KL = 0.300412\n",
      "  JS divergence = 0.069720\n",
      "Wasserstein-1距离 between data4 and data5: 0.623902\n",
      "\n",
      "KL散度计算完成！\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# 计算KL散度的函数\n",
    "def calculate_kl_divergence(p, q, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    计算两个概率分布之间的KL散度\n",
    "    \"\"\"\n",
    "    # 添加小的epsilon值以避免除零错误\n",
    "    p = p + epsilon\n",
    "    q = q + epsilon\n",
    "    \n",
    "    # 归一化为概率分布\n",
    "    p = p / np.sum(p)\n",
    "    q = q / np.sum(q)\n",
    "    \n",
    "    # 计算KL散度\n",
    "    return entropy(p, q)\n",
    "\n",
    "# 将复数数据转换为幅度\n",
    "def complex_to_magnitude(data):\n",
    "    \"\"\"\n",
    "    将复数数据转换为幅度\n",
    "    \"\"\"\n",
    "    return np.abs(data)\n",
    "\n",
    "# 计算所有known_env数据对之间的KL散度\n",
    "kl_divergences = []\n",
    "js_divergences = []\n",
    "wasserstein_distances = []\n",
    "\n",
    "print(\"计算known_env中两两之间数据的KL散度...\")\n",
    "\n",
    "# 将复数数据转换为幅度并展平\n",
    "magnitude_data = []\n",
    "for i, env_data in enumerate(known_env):\n",
    "    mag_data = complex_to_magnitude(env_data)\n",
    "    # 展平数据以便计算KL散度\n",
    "    flattened_data = mag_data.flatten()\n",
    "    magnitude_data.append(flattened_data)\n",
    "    print(f\"data{i+1} shape: {flattened_data.shape}\")\n",
    "\n",
    "# 计算两两之间的KL散度\n",
    "for i in range(len(magnitude_data)):\n",
    "    for j in range(i+1, len(magnitude_data)):\n",
    "        # 确保两个分布具有相同的长度\n",
    "        min_len = min(len(magnitude_data[i]), len(magnitude_data[j]))\n",
    "        p = magnitude_data[i][:min_len]\n",
    "        q = magnitude_data[j][:min_len]\n",
    "        \n",
    "        # 计算KL散度 (D_KL(P||Q) 和 D_KL(Q||P))\n",
    "        kl_pq = calculate_kl_divergence(p, q)\n",
    "        kl_qp = calculate_kl_divergence(q, p)\n",
    "        \n",
    "        # 计算对称KL散度\n",
    "        sym_kl = (kl_pq + kl_qp) / 2\n",
    "        \n",
    "        # 计算JS散度作为另一种度量\n",
    "        js_div = jensenshannon(p/np.sum(p), q/np.sum(q))**2\n",
    "        js_divergences.append({\n",
    "            'pair': (i+1, j+1),\n",
    "            'JS divergence': js_div\n",
    "        })\n",
    "\n",
    "        w_dist = wasserstein_distance(p, q)\n",
    "        wasserstein_distances.append({\n",
    "            'pair': (i+1, j+1),\n",
    "            'Wasserstein-1 distance': w_dist\n",
    "        })\n",
    "        \n",
    "        print(f\"Wasserstein-1距离 between data{i+1} and data{j+1}: {w_dist:.6f}\")\n",
    "\n",
    "        kl_divergences.append({\n",
    "            'pair': (i+1, j+1),\n",
    "            'KL(P||Q)': kl_pq,\n",
    "            'KL(Q||P)': kl_qp,\n",
    "            'Symmetric KL': sym_kl,\n",
    "            'JS divergence': js_div\n",
    "        })\n",
    "        \n",
    "        print(f\"KL散度 between data{i+1} and data{j+1}:\")\n",
    "        print(f\"  D_KL(P||Q) = {kl_pq:.6f}\")\n",
    "        print(f\"  D_KL(Q||P) = {kl_qp:.6f}\")\n",
    "        print(f\"  Symmetric KL = {sym_kl:.6f}\")\n",
    "        print(f\"  JS divergence = {js_div:.6f}\")\n",
    "        print(f\"Wasserstein-1距离 between data{i+1} and data{j+1}: {w_dist:.6f}\")\n",
    "        print()\n",
    "\n",
    "print(\"KL散度计算完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wasserstein_distance_calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "model_path = [f'/mnt/data/WQ/LoRAT/model/exp_Argos_4_30/FT_Client{i}/lora/lora_weights.pt' for i in [0, 1, 2, 3, 5]]\n",
    "known_models = [torch.load(path) for path in model_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "model_similarity_calculation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算known_models中两两模型之间的相似度...\n",
      "model0 flattened shape: torch.Size([294912])\n",
      "model1 flattened shape: torch.Size([294912])\n",
      "model2 flattened shape: torch.Size([294912])\n",
      "model3 flattened shape: torch.Size([294912])\n",
      "model4 flattened shape: torch.Size([294912])\n",
      "模型 0 和模型 1 之间的相似度:\n",
      "  L1距离: 9266.748047\n",
      "  L2距离: 36.498940\n",
      "  Normalized L1距离: 0.031422\n",
      "  Normalized L2距离: 0.067210\n",
      "  Cosine相似度: 0.472261\n",
      "\n",
      "模型 0 和模型 2 之间的相似度:\n",
      "  L1距离: 7685.079102\n",
      "  L2距离: 31.785244\n",
      "  Normalized L1距离: 0.026059\n",
      "  Normalized L2距离: 0.058530\n",
      "  Cosine相似度: 0.692073\n",
      "\n",
      "模型 0 和模型 3 之间的相似度:\n",
      "  L1距离: 8851.396484\n",
      "  L2距离: 36.846680\n",
      "  Normalized L1距离: 0.030014\n",
      "  Normalized L2距离: 0.067850\n",
      "  Cosine相似度: 0.528995\n",
      "\n",
      "模型 0 和模型 4 之间的相似度:\n",
      "  L1距离: 8375.241211\n",
      "  L2距离: 32.722618\n",
      "  Normalized L1距离: 0.028399\n",
      "  Normalized L2距离: 0.060256\n",
      "  Cosine相似度: 0.543656\n",
      "\n",
      "模型 1 和模型 2 之间的相似度:\n",
      "  L1距离: 9899.349609\n",
      "  L2距离: 38.820587\n",
      "  Normalized L1距离: 0.033567\n",
      "  Normalized L2距离: 0.071485\n",
      "  Cosine相似度: 0.459963\n",
      "\n",
      "模型 1 和模型 3 之间的相似度:\n",
      "  L1距离: 8740.822266\n",
      "  L2距离: 34.703926\n",
      "  Normalized L1距离: 0.029639\n",
      "  Normalized L2距离: 0.063905\n",
      "  Cosine相似度: 0.484340\n",
      "\n",
      "模型 1 和模型 4 之间的相似度:\n",
      "  L1距离: 5690.311523\n",
      "  L2距离: 22.127794\n",
      "  Normalized L1距离: 0.019295\n",
      "  Normalized L2距离: 0.040747\n",
      "  Cosine相似度: 0.693350\n",
      "\n",
      "模型 2 和模型 3 之间的相似度:\n",
      "  L1距离: 9320.039062\n",
      "  L2距离: 38.534988\n",
      "  Normalized L1距离: 0.031603\n",
      "  Normalized L2距离: 0.070959\n",
      "  Cosine相似度: 0.525235\n",
      "\n",
      "模型 2 和模型 4 之间的相似度:\n",
      "  L1距离: 9208.380859\n",
      "  L2距离: 35.917381\n",
      "  Normalized L1距离: 0.031224\n",
      "  Normalized L2距离: 0.066139\n",
      "  Cosine相似度: 0.510071\n",
      "\n",
      "模型 3 和模型 4 之间的相似度:\n",
      "  L1距离: 7920.969727\n",
      "  L2距离: 30.739197\n",
      "  Normalized L1距离: 0.026859\n",
      "  Normalized L2距离: 0.056604\n",
      "  Cosine相似度: 0.551681\n",
      "\n",
      "模型相似度计算完成，结果已保存到 /mnt/data/WQ/LoRAT/model_similarities.json\n"
     ]
    }
   ],
   "source": [
    "# 计算模型之间相似度的函数\n",
    "def flatten_model_weights(model_state_dict):\n",
    "    \"\"\"\n",
    "    将模型权重展平为一维向量\n",
    "    \"\"\"\n",
    "    flattened_weights = []\n",
    "    for key in sorted(model_state_dict.keys()):  # 排序以确保一致性\n",
    "        flattened_weights.append(model_state_dict[key].flatten())\n",
    "    return torch.cat(flattened_weights)\n",
    "\n",
    "# 计算normalized l1/l2 distance和cosine similarity\n",
    "model_similarities = []\n",
    "\n",
    "print(\"计算known_models中两两模型之间的相似度...\")\n",
    "\n",
    "# 将模型权重展平\n",
    "flattened_models = []\n",
    "for i, model in enumerate(known_models):\n",
    "    flattened_model = flatten_model_weights(model)\n",
    "    flattened_models.append(flattened_model)\n",
    "    print(f\"model{i} flattened shape: {flattened_model.shape}\")\n",
    "\n",
    "# 计算两两之间的相似度\n",
    "for i in range(len(flattened_models)):\n",
    "    for j in range(i+1, len(flattened_models)):\n",
    "        model1 = flattened_models[i]\n",
    "        model2 = flattened_models[j]\n",
    "        \n",
    "        # 计算l1距离\n",
    "        l1_distance = torch.norm(model1 - model2, p=1).item()\n",
    "        \n",
    "        # 计算l2距离\n",
    "        l2_distance = torch.norm(model1 - model2, p=2).item()\n",
    "        \n",
    "        # 计算normalized l1距离\n",
    "        normalized_l1 = l1_distance / len(model1)\n",
    "        \n",
    "        # 计算normalized l2距离\n",
    "        normalized_l2 = l2_distance / np.sqrt(len(model1))\n",
    "        \n",
    "        # 计算cosine similarity\n",
    "        cosine_sim = F.cosine_similarity(model1.unsqueeze(0), model2.unsqueeze(0)).item()\n",
    "        \n",
    "        model_similarities.append({\n",
    "            'pair': (i, j),\n",
    "            'l1_distance': l1_distance,\n",
    "            'l2_distance': l2_distance,\n",
    "            'normalized_l1': normalized_l1,\n",
    "            'normalized_l2': normalized_l2,\n",
    "            'cosine_similarity': cosine_sim\n",
    "        })\n",
    "        \n",
    "        print(f\"模型 {i} 和模型 {j} 之间的相似度:\")\n",
    "        print(f\"  L1距离: {l1_distance:.6f}\")\n",
    "        print(f\"  L2距离: {l2_distance:.6f}\")\n",
    "        print(f\"  Normalized L1距离: {normalized_l1:.6f}\")\n",
    "        print(f\"  Normalized L2距离: {normalized_l2:.6f}\")\n",
    "        print(f\"  Cosine相似度: {cosine_sim:.6f}\")\n",
    "        print()\n",
    "\n",
    "# # 保存结果\n",
    "# import json\n",
    "# def convert_tensor(obj):\n",
    "#     if isinstance(obj, torch.Tensor):\n",
    "#         return obj.item()\n",
    "#     raise TypeError(f'Object of type {type(obj)} is not JSON serializable')\n",
    "\n",
    "# with open('/mnt/data/WQ/LoRAT/model_similarities.json', 'w') as f:\n",
    "#     json.dump(model_similarities, f, indent=2, default=convert_tensor)\n",
    "\n",
    "print(\"模型相似度计算完成，结果已保存到 /mnt/data/WQ/LoRAT/model_similarities.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "separate_neural_networks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备训练数据...\n",
      "输入特征形状: (10, 5)\n",
      "输出目标形状: (10, 5)\n",
      "\n",
      "开始训练多个神经网络模型...\n",
      "\n",
      "训练模型: KL(P||Q) -> L1 distance\n",
      "  Epoch [100/500], Train Loss: 0.499674\n",
      "  Epoch [200/500], Train Loss: 0.206161\n",
      "  Epoch [300/500], Train Loss: 0.129086\n",
      "  Epoch [400/500], Train Loss: 0.105408\n",
      "  Epoch [500/500], Train Loss: 0.048097\n",
      "  训练集MSE: 0.082996\n",
      "  模型已保存: KL(P||Q)_L1_distance.pth\n",
      "\n",
      "训练模型: KL(P||Q) -> L2 distance\n",
      "  Epoch [100/500], Train Loss: 0.109878\n",
      "  Epoch [200/500], Train Loss: 0.087063\n",
      "  Epoch [300/500], Train Loss: 0.100814\n",
      "  Epoch [400/500], Train Loss: 0.074222\n",
      "  Epoch [500/500], Train Loss: 0.115106\n",
      "  训练集MSE: 0.063785\n",
      "  模型已保存: KL(P||Q)_L2_distance.pth\n",
      "\n",
      "训练模型: KL(P||Q) -> Normalized L1\n",
      "  Epoch [100/500], Train Loss: 0.240038\n",
      "  Epoch [200/500], Train Loss: 0.109449\n",
      "  Epoch [300/500], Train Loss: 0.216100\n",
      "  Epoch [400/500], Train Loss: 0.105610\n",
      "  Epoch [500/500], Train Loss: 0.093667\n",
      "  训练集MSE: 0.076391\n",
      "  模型已保存: KL(P||Q)_Normalized_L1.pth\n",
      "\n",
      "训练模型: KL(P||Q) -> Normalized L2\n",
      "  Epoch [100/500], Train Loss: 0.104171\n",
      "  Epoch [200/500], Train Loss: 0.105180\n",
      "  Epoch [300/500], Train Loss: 0.068833\n",
      "  Epoch [400/500], Train Loss: 0.141279\n",
      "  Epoch [500/500], Train Loss: 0.078821\n",
      "  训练集MSE: 0.063330\n",
      "  模型已保存: KL(P||Q)_Normalized_L2.pth\n",
      "\n",
      "训练模型: KL(P||Q) -> Cosine similarity\n",
      "  Epoch [100/500], Train Loss: 0.229133\n",
      "  Epoch [200/500], Train Loss: 0.449597\n",
      "  Epoch [300/500], Train Loss: 0.307936\n",
      "  Epoch [400/500], Train Loss: 0.296833\n",
      "  Epoch [500/500], Train Loss: 0.218355\n",
      "  训练集MSE: 0.233721\n",
      "  模型已保存: KL(P||Q)_Cosine_similarity.pth\n",
      "\n",
      "训练模型: KL(Q||P) -> L1 distance\n",
      "  Epoch [100/500], Train Loss: 0.348403\n",
      "  Epoch [200/500], Train Loss: 0.191629\n",
      "  Epoch [300/500], Train Loss: 0.099249\n",
      "  Epoch [400/500], Train Loss: 0.224845\n",
      "  Epoch [500/500], Train Loss: 0.100943\n",
      "  训练集MSE: 0.090557\n",
      "  模型已保存: KL(Q||P)_L1_distance.pth\n",
      "\n",
      "训练模型: KL(Q||P) -> L2 distance\n",
      "  Epoch [100/500], Train Loss: 0.389574\n",
      "  Epoch [200/500], Train Loss: 0.308853\n",
      "  Epoch [300/500], Train Loss: 0.104285\n",
      "  Epoch [400/500], Train Loss: 0.094910\n",
      "  Epoch [500/500], Train Loss: 0.088589\n",
      "  训练集MSE: 0.075030\n",
      "  模型已保存: KL(Q||P)_L2_distance.pth\n",
      "\n",
      "训练模型: KL(Q||P) -> Normalized L1\n",
      "  Epoch [100/500], Train Loss: 0.782426\n",
      "  Epoch [200/500], Train Loss: 0.162417\n",
      "  Epoch [300/500], Train Loss: 0.119792\n",
      "  Epoch [400/500], Train Loss: 0.173250\n",
      "  Epoch [500/500], Train Loss: 0.213307\n",
      "  训练集MSE: 0.083336\n",
      "  模型已保存: KL(Q||P)_Normalized_L1.pth\n",
      "\n",
      "训练模型: KL(Q||P) -> Normalized L2\n",
      "  Epoch [100/500], Train Loss: 0.346164\n",
      "  Epoch [200/500], Train Loss: 0.097017\n",
      "  Epoch [300/500], Train Loss: 0.181493\n",
      "  Epoch [400/500], Train Loss: 0.109625\n",
      "  Epoch [500/500], Train Loss: 0.083351\n",
      "  训练集MSE: 0.067951\n",
      "  模型已保存: KL(Q||P)_Normalized_L2.pth\n",
      "\n",
      "训练模型: KL(Q||P) -> Cosine similarity\n",
      "  Epoch [100/500], Train Loss: 0.387209\n",
      "  Epoch [200/500], Train Loss: 0.379127\n",
      "  Epoch [300/500], Train Loss: 0.204891\n",
      "  Epoch [400/500], Train Loss: 0.230631\n",
      "  Epoch [500/500], Train Loss: 0.270737\n",
      "  训练集MSE: 0.167088\n",
      "  模型已保存: KL(Q||P)_Cosine_similarity.pth\n",
      "\n",
      "训练模型: Symmetric KL -> L1 distance\n",
      "  Epoch [100/500], Train Loss: 0.263014\n",
      "  Epoch [200/500], Train Loss: 0.073384\n",
      "  Epoch [300/500], Train Loss: 0.133957\n",
      "  Epoch [400/500], Train Loss: 0.074671\n",
      "  Epoch [500/500], Train Loss: 0.081808\n",
      "  训练集MSE: 0.072038\n",
      "  模型已保存: Symmetric_KL_L1_distance.pth\n",
      "\n",
      "训练模型: Symmetric KL -> L2 distance\n",
      "  Epoch [100/500], Train Loss: 0.089717\n",
      "  Epoch [200/500], Train Loss: 0.053891\n",
      "  Epoch [300/500], Train Loss: 0.057352\n",
      "  Epoch [400/500], Train Loss: 0.068140\n",
      "  Epoch [500/500], Train Loss: 0.029225\n",
      "  训练集MSE: 0.055712\n",
      "  模型已保存: Symmetric_KL_L2_distance.pth\n",
      "\n",
      "训练模型: Symmetric KL -> Normalized L1\n",
      "  Epoch [100/500], Train Loss: 0.189719\n",
      "  Epoch [200/500], Train Loss: 0.127320\n",
      "  Epoch [300/500], Train Loss: 0.131105\n",
      "  Epoch [400/500], Train Loss: 0.074436\n",
      "  Epoch [500/500], Train Loss: 0.132362\n",
      "  训练集MSE: 0.074512\n",
      "  模型已保存: Symmetric_KL_Normalized_L1.pth\n",
      "\n",
      "训练模型: Symmetric KL -> Normalized L2\n",
      "  Epoch [100/500], Train Loss: 0.375752\n",
      "  Epoch [200/500], Train Loss: 0.246359\n",
      "  Epoch [300/500], Train Loss: 0.072292\n",
      "  Epoch [400/500], Train Loss: 0.115693\n",
      "  Epoch [500/500], Train Loss: 0.066012\n",
      "  训练集MSE: 0.061558\n",
      "  模型已保存: Symmetric_KL_Normalized_L2.pth\n",
      "\n",
      "训练模型: Symmetric KL -> Cosine similarity\n",
      "  Epoch [100/500], Train Loss: 0.336712\n",
      "  Epoch [200/500], Train Loss: 0.494216\n",
      "  Epoch [300/500], Train Loss: 0.298039\n",
      "  Epoch [400/500], Train Loss: 0.226664\n",
      "  Epoch [500/500], Train Loss: 0.372263\n",
      "  训练集MSE: 0.188819\n",
      "  模型已保存: Symmetric_KL_Cosine_similarity.pth\n",
      "\n",
      "训练模型: JS divergence -> L1 distance\n",
      "  Epoch [100/500], Train Loss: 0.299954\n",
      "  Epoch [200/500], Train Loss: 0.269844\n",
      "  Epoch [300/500], Train Loss: 0.097133\n",
      "  Epoch [400/500], Train Loss: 0.103870\n",
      "  Epoch [500/500], Train Loss: 0.069197\n",
      "  训练集MSE: 0.054886\n",
      "  模型已保存: JS_divergence_L1_distance.pth\n",
      "\n",
      "训练模型: JS divergence -> L2 distance\n",
      "  Epoch [100/500], Train Loss: 0.196985\n",
      "  Epoch [200/500], Train Loss: 0.088399\n",
      "  Epoch [300/500], Train Loss: 0.099020\n",
      "  Epoch [400/500], Train Loss: 0.076880\n",
      "  Epoch [500/500], Train Loss: 0.184986\n",
      "  训练集MSE: 0.045242\n",
      "  模型已保存: JS_divergence_L2_distance.pth\n",
      "\n",
      "训练模型: JS divergence -> Normalized L1\n",
      "  Epoch [100/500], Train Loss: 0.258691\n",
      "  Epoch [200/500], Train Loss: 0.127342\n",
      "  Epoch [300/500], Train Loss: 0.083322\n",
      "  Epoch [400/500], Train Loss: 0.127325\n",
      "  Epoch [500/500], Train Loss: 0.055922\n",
      "  训练集MSE: 0.039297\n",
      "  模型已保存: JS_divergence_Normalized_L1.pth\n",
      "\n",
      "训练模型: JS divergence -> Normalized L2\n",
      "  Epoch [100/500], Train Loss: 0.155788\n",
      "  Epoch [200/500], Train Loss: 0.082896\n",
      "  Epoch [300/500], Train Loss: 0.104257\n",
      "  Epoch [400/500], Train Loss: 0.066275\n",
      "  Epoch [500/500], Train Loss: 0.083775\n",
      "  训练集MSE: 0.047232\n",
      "  模型已保存: JS_divergence_Normalized_L2.pth\n",
      "\n",
      "训练模型: JS divergence -> Cosine similarity\n",
      "  Epoch [100/500], Train Loss: 0.248058\n",
      "  Epoch [200/500], Train Loss: 0.298534\n",
      "  Epoch [300/500], Train Loss: 0.251135\n",
      "  Epoch [400/500], Train Loss: 0.106816\n",
      "  Epoch [500/500], Train Loss: 0.451190\n",
      "  训练集MSE: 0.081327\n",
      "  模型已保存: JS_divergence_Cosine_similarity.pth\n",
      "\n",
      "训练模型: Wasserstein-1 distance -> L1 distance\n",
      "  Epoch [100/500], Train Loss: 0.222140\n",
      "  Epoch [200/500], Train Loss: 0.153135\n",
      "  Epoch [300/500], Train Loss: 0.102225\n",
      "  Epoch [400/500], Train Loss: 0.120929\n",
      "  Epoch [500/500], Train Loss: 0.156537\n",
      "  训练集MSE: 0.052995\n",
      "  模型已保存: Wasserstein-1_distance_L1_distance.pth\n",
      "\n",
      "训练模型: Wasserstein-1 distance -> L2 distance\n",
      "  Epoch [100/500], Train Loss: 0.202593\n",
      "  Epoch [200/500], Train Loss: 0.349124\n",
      "  Epoch [300/500], Train Loss: 0.126153\n",
      "  Epoch [400/500], Train Loss: 0.041400\n",
      "  Epoch [500/500], Train Loss: 0.025377\n",
      "  训练集MSE: 0.026991\n",
      "  模型已保存: Wasserstein-1_distance_L2_distance.pth\n",
      "\n",
      "训练模型: Wasserstein-1 distance -> Normalized L1\n",
      "  Epoch [100/500], Train Loss: 0.337280\n",
      "  Epoch [200/500], Train Loss: 0.164562\n",
      "  Epoch [300/500], Train Loss: 0.101929\n",
      "  Epoch [400/500], Train Loss: 0.028770\n",
      "  Epoch [500/500], Train Loss: 0.051464\n",
      "  训练集MSE: 0.022156\n",
      "  模型已保存: Wasserstein-1_distance_Normalized_L1.pth\n",
      "\n",
      "训练模型: Wasserstein-1 distance -> Normalized L2\n",
      "  Epoch [100/500], Train Loss: 0.184162\n",
      "  Epoch [200/500], Train Loss: 0.127602\n",
      "  Epoch [300/500], Train Loss: 0.158504\n",
      "  Epoch [400/500], Train Loss: 0.143809\n",
      "  Epoch [500/500], Train Loss: 0.025384\n",
      "  训练集MSE: 0.003416\n",
      "  模型已保存: Wasserstein-1_distance_Normalized_L2.pth\n",
      "\n",
      "训练模型: Wasserstein-1 distance -> Cosine similarity\n",
      "  Epoch [100/500], Train Loss: 0.492801\n",
      "  Epoch [200/500], Train Loss: 0.458334\n",
      "  Epoch [300/500], Train Loss: 0.260408\n",
      "  Epoch [400/500], Train Loss: 0.118159\n",
      "  Epoch [500/500], Train Loss: 0.064560\n",
      "  训练集MSE: 0.072058\n",
      "  模型已保存: Wasserstein-1_distance_Cosine_similarity.pth\n",
      "\n",
      "所有模型训练完成!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 创建保存目录\n",
    "os.makedirs('/mnt/data/WQ/LoRAT/mapping_model', exist_ok=True)\n",
    "\n",
    "# 定义神经网络模型\n",
    "class DistributionToModelMapper(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DistributionToModelMapper, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc4 = nn.Linear(hidden_dim//2, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据\n",
    "print(\"准备训练数据...\")\n",
    "\n",
    "# 构建输入特征和输出目标\n",
    "input_features = []\n",
    "output_targets = []\n",
    "data_pairs = []\n",
    "model_pairs = []\n",
    "\n",
    "# 收集数据分布散度和模型距离\n",
    "for i, kl_div in enumerate(kl_divergences):\n",
    "    pair = kl_div['pair']\n",
    "    kl_pq = kl_div['KL(P||Q)']\n",
    "    kl_qp = kl_div['KL(Q||P)']\n",
    "    sym_kl = kl_div['Symmetric KL']\n",
    "    js_div = js_divergences[i]['JS divergence']\n",
    "    w_dist = wasserstein_distances[i]['Wasserstein-1 distance']\n",
    "    \n",
    "    # 收集模型相似度\n",
    "    model_sim = model_similarities[i]\n",
    "    model_pair = model_sim['pair']\n",
    "    l1_dist = model_sim['l1_distance']\n",
    "    l2_dist = model_sim['l2_distance']\n",
    "    norm_l1 = model_sim['normalized_l1']\n",
    "    norm_l2 = model_sim['normalized_l2']\n",
    "    cosine_sim = model_sim['cosine_similarity']\n",
    "    \n",
    "    # 确保数据对齐\n",
    "    if pair == (model_pair[0]+1, model_pair[1]+1):  # 数据索引从1开始，模型索引从0开始\n",
    "        # 输入特征：[KL(P||Q), KL(Q||P), Symmetric KL, JS divergence, Wasserstein-1 distance]\n",
    "        input_features.append([kl_pq, kl_qp, sym_kl, js_div, w_dist])\n",
    "        # 输出目标：[L1距离, L2距离, Normalized L1, Normalized L2, Cosine相似度]\n",
    "        output_targets.append([l1_dist, l2_dist, norm_l1, norm_l2, cosine_sim])\n",
    "        \n",
    "        data_pairs.append(pair)\n",
    "        model_pairs.append(model_pair)\n",
    "\n",
    "# 转换为numpy数组\n",
    "X = np.array(input_features)\n",
    "y = np.array(output_targets)\n",
    "\n",
    "print(f\"输入特征形状: {X.shape}\")\n",
    "print(f\"输出目标形状: {y.shape}\")\n",
    "\n",
    "# 定义不同的输入输出组合\n",
    "input_names = ['KL(P||Q)', 'KL(Q||P)', 'Symmetric KL', 'JS divergence', 'Wasserstein-1 distance']\n",
    "output_names = ['L1 distance', 'L2 distance', 'Normalized L1', 'Normalized L2', 'Cosine similarity']\n",
    "\n",
    "# 训练多个模型，每个模型使用一种输入特征预测一种输出目标\n",
    "trained_models = {}\n",
    "scalers = {}\n",
    "\n",
    "print(\"\\n开始训练多个神经网络模型...\")\n",
    "\n",
    "# 为每种输入输出组合训练一个模型\n",
    "for input_idx, input_name in enumerate(input_names):\n",
    "    for output_idx, output_name in enumerate(output_names):\n",
    "        print(f\"\\n训练模型: {input_name} -> {output_name}\")\n",
    "        \n",
    "        # 准备数据\n",
    "        X_single = X[:, input_idx].reshape(-1, 1)  # 只使用一种输入特征\n",
    "        y_single = y[:, output_idx].reshape(-1, 1)  # 只预测一种输出目标\n",
    "        \n",
    "        # 数据标准化\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        \n",
    "        X_scaled = scaler_X.fit_transform(X_single)\n",
    "        y_scaled = scaler_y.fit_transform(y_single)\n",
    "        \n",
    "        # 划分训练集和测试集\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.0, random_state=42)\n",
    "        X_train, y_train = X_scaled, y_scaled\n",
    "        \n",
    "        # 转换为PyTorch张量\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        # X_test_tensor = torch.FloatTensor(X_test)\n",
    "        # y_test_tensor = torch.FloatTensor(y_test)\n",
    "        \n",
    "        # 初始化模型\n",
    "        model = DistributionToModelMapper(1, 32, 1)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        \n",
    "        # 训练模型\n",
    "        num_epochs = 500\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # # 测试阶段\n",
    "            # model.eval()\n",
    "            # with torch.no_grad():\n",
    "            #     test_outputs = model(X_test_tensor)\n",
    "            #     test_loss = criterion(test_outputs, y_test_tensor)\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            # test_losses.append(test_loss.item())\n",
    "            \n",
    "            # 每100个epoch打印一次\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f'  Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.6f}')\n",
    "        \n",
    "        # 评估模型\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_predictions = model(X_train_tensor)\n",
    "            # test_predictions = model(X_test_tensor)\n",
    "            \n",
    "            train_mse = criterion(train_predictions, y_train_tensor)\n",
    "            # test_mse = criterion(test_predictions, y_test_tensor)\n",
    "            \n",
    "            print(f\"  训练集MSE: {train_mse.item():.6f}\")\n",
    "            # print(f\"  测试集MSE: {test_mse.item():.6f}\")\n",
    "        \n",
    "        # 保存模型和缩放器\n",
    "        model_key = f\"{input_name.replace(' ', '_')}_{output_name.replace(' ', '_')}\"\n",
    "        trained_models[model_key] = model\n",
    "        scalers[model_key] = (scaler_X, scaler_y)\n",
    "        \n",
    "        # 保存模型\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'scaler_X': scaler_X,\n",
    "            'scaler_y': scaler_y,\n",
    "        }, f'/mnt/data/WQ/LoRAT/mapping_model/{model_key}.pth')\n",
    "        \n",
    "        print(f\"  模型已保存: {model_key}.pth\")\n",
    "\n",
    "print(\"\\n所有模型训练完成!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1ef61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "计算unknown_env与known_env之间的分布散度...\n",
      "unknown_env0 shape: (261352,)\n",
      "unknown_env0 与 known_env0 之间的散度:\n",
      "  KL(P||Q) = 0.402975\n",
      "  KL(Q||P) = 0.377520\n",
      "  Symmetric KL = 0.390248\n",
      "  JS divergence = 0.087166\n",
      "  Wasserstein-1 distance = 0.525469\n",
      "\n",
      "unknown_env0 与 known_env1 之间的散度:\n",
      "  KL(P||Q) = 0.435871\n",
      "  KL(Q||P) = 0.438831\n",
      "  Symmetric KL = 0.437351\n",
      "  JS divergence = 0.097759\n",
      "  Wasserstein-1 distance = 0.567214\n",
      "\n",
      "unknown_env0 与 known_env2 之间的散度:\n",
      "  KL(P||Q) = 0.329105\n",
      "  KL(Q||P) = 0.313058\n",
      "  Symmetric KL = 0.321081\n",
      "  JS divergence = 0.072202\n",
      "  Wasserstein-1 distance = 0.205136\n",
      "\n",
      "unknown_env0 与 known_env3 之间的散度:\n",
      "  KL(P||Q) = 0.433360\n",
      "  KL(Q||P) = 0.417531\n",
      "  Symmetric KL = 0.425445\n",
      "  JS divergence = 0.095445\n",
      "  Wasserstein-1 distance = 0.424546\n",
      "\n",
      "unknown_env0 与 known_env4 之间的散度:\n",
      "  KL(P||Q) = 0.212722\n",
      "  KL(Q||P) = 0.242385\n",
      "  Symmetric KL = 0.227554\n",
      "  JS divergence = 0.053372\n",
      "  Wasserstein-1 distance = 0.501348\n",
      "\n",
      "\n",
      "使用训练好的模型预测unknown_env与known_env之间的模型距离...\n",
      "\n",
      "预测 unknown_env0 与 known_env0 之间的模型距离:\n",
      "  KL(P||Q) -> L1 distance: 9676.680664\n",
      "  KL(P||Q) -> L2 distance: 38.781403\n",
      "  KL(P||Q) -> Normalized L1: 0.033326\n",
      "  KL(P||Q) -> Normalized L2: 0.070953\n",
      "  KL(P||Q) -> Cosine similarity: 0.466661\n",
      "  KL(Q||P) -> L1 distance: 9919.965820\n",
      "  KL(Q||P) -> L2 distance: 37.810745\n",
      "  KL(Q||P) -> Normalized L1: 0.032522\n",
      "  KL(Q||P) -> Normalized L2: 0.068899\n",
      "  KL(Q||P) -> Cosine similarity: 0.553067\n",
      "  Symmetric KL -> L1 distance: 9687.348633\n",
      "  Symmetric KL -> L2 distance: 38.289379\n",
      "  Symmetric KL -> Normalized L1: 0.032758\n",
      "  Symmetric KL -> Normalized L2: 0.070557\n",
      "  Symmetric KL -> Cosine similarity: 0.457882\n",
      "  JS divergence -> L1 distance: 9701.799805\n",
      "  JS divergence -> L2 distance: 38.540901\n",
      "  JS divergence -> Normalized L1: 0.033414\n",
      "  JS divergence -> Normalized L2: 0.071322\n",
      "  JS divergence -> Cosine similarity: 0.472438\n",
      "  Wasserstein-1 distance -> L1 distance: 9636.652344\n",
      "  Wasserstein-1 distance -> L2 distance: 37.905769\n",
      "  Wasserstein-1 distance -> Normalized L1: 0.033500\n",
      "  Wasserstein-1 distance -> Normalized L2: 0.069498\n",
      "  Wasserstein-1 distance -> Cosine similarity: 0.504132\n",
      "\n",
      "预测 unknown_env0 与 known_env1 之间的模型距离:\n",
      "  KL(P||Q) -> L1 distance: 9389.762695\n",
      "  KL(P||Q) -> L2 distance: 37.126968\n",
      "  KL(P||Q) -> Normalized L1: 0.032173\n",
      "  KL(P||Q) -> Normalized L2: 0.067599\n",
      "  KL(P||Q) -> Cosine similarity: 0.475518\n",
      "  KL(Q||P) -> L1 distance: 9091.049805\n",
      "  KL(Q||P) -> L2 distance: 36.658718\n",
      "  KL(Q||P) -> Normalized L1: 0.030459\n",
      "  KL(Q||P) -> Normalized L2: 0.066494\n",
      "  KL(Q||P) -> Cosine similarity: 0.496760\n",
      "  Symmetric KL -> L1 distance: 9009.925781\n",
      "  Symmetric KL -> L2 distance: 37.030174\n",
      "  Symmetric KL -> Normalized L1: 0.031150\n",
      "  Symmetric KL -> Normalized L2: 0.068032\n",
      "  Symmetric KL -> Cosine similarity: 0.466342\n",
      "  JS divergence -> L1 distance: 9054.257812\n",
      "  JS divergence -> L2 distance: 37.012985\n",
      "  JS divergence -> Normalized L1: 0.032345\n",
      "  JS divergence -> Normalized L2: 0.067938\n",
      "  JS divergence -> Cosine similarity: 0.471597\n",
      "  Wasserstein-1 distance -> L1 distance: 9497.195312\n",
      "  Wasserstein-1 distance -> L2 distance: 35.980919\n",
      "  Wasserstein-1 distance -> Normalized L1: 0.030357\n",
      "  Wasserstein-1 distance -> Normalized L2: 0.061958\n",
      "  Wasserstein-1 distance -> Cosine similarity: 0.505163\n",
      "\n",
      "预测 unknown_env0 与 known_env2 之间的模型距离:\n",
      "  KL(P||Q) -> L1 distance: 6336.973633\n",
      "  KL(P||Q) -> L2 distance: 22.761778\n",
      "  KL(P||Q) -> Normalized L1: 0.019271\n",
      "  KL(P||Q) -> Normalized L2: 0.043977\n",
      "  KL(P||Q) -> Cosine similarity: 0.621096\n",
      "  KL(Q||P) -> L1 distance: 7877.602051\n",
      "  KL(Q||P) -> L2 distance: 32.017349\n",
      "  KL(Q||P) -> Normalized L1: 0.026650\n",
      "  KL(Q||P) -> Normalized L2: 0.057191\n",
      "  KL(Q||P) -> Cosine similarity: 0.612817\n",
      "  Symmetric KL -> L1 distance: 5601.561523\n",
      "  Symmetric KL -> L2 distance: 23.303289\n",
      "  Symmetric KL -> Normalized L1: 0.019341\n",
      "  Symmetric KL -> Normalized L2: 0.042075\n",
      "  Symmetric KL -> Cosine similarity: 0.647126\n",
      "  JS divergence -> L1 distance: 6966.584961\n",
      "  JS divergence -> L2 distance: 26.452759\n",
      "  JS divergence -> Normalized L1: 0.024200\n",
      "  JS divergence -> Normalized L2: 0.047824\n",
      "  JS divergence -> Cosine similarity: 0.604647\n",
      "  Wasserstein-1 distance -> L1 distance: 9292.312500\n",
      "  Wasserstein-1 distance -> L2 distance: 34.734791\n",
      "  Wasserstein-1 distance -> Normalized L1: 0.030403\n",
      "  Wasserstein-1 distance -> Normalized L2: 0.064682\n",
      "  Wasserstein-1 distance -> Cosine similarity: 0.492536\n",
      "\n",
      "预测 unknown_env0 与 known_env3 之间的模型距离:\n",
      "  KL(P||Q) -> L1 distance: 9416.111328\n",
      "  KL(P||Q) -> L2 distance: 37.254719\n",
      "  KL(P||Q) -> Normalized L1: 0.032264\n",
      "  KL(P||Q) -> Normalized L2: 0.067652\n",
      "  KL(P||Q) -> Cosine similarity: 0.474842\n",
      "  KL(Q||P) -> L1 distance: 9393.890625\n",
      "  KL(Q||P) -> L2 distance: 36.805496\n",
      "  KL(Q||P) -> Normalized L1: 0.030861\n",
      "  KL(Q||P) -> Normalized L2: 0.066362\n",
      "  KL(Q||P) -> Cosine similarity: 0.481910\n",
      "  Symmetric KL -> L1 distance: 9119.909180\n",
      "  Symmetric KL -> L2 distance: 37.405350\n",
      "  Symmetric KL -> Normalized L1: 0.032017\n",
      "  Symmetric KL -> Normalized L2: 0.069195\n",
      "  Symmetric KL -> Cosine similarity: 0.463236\n",
      "  JS divergence -> L1 distance: 9196.468750\n",
      "  JS divergence -> L2 distance: 37.394691\n",
      "  JS divergence -> Normalized L1: 0.032940\n",
      "  JS divergence -> Normalized L2: 0.069870\n",
      "  JS divergence -> Cosine similarity: 0.472132\n",
      "  Wasserstein-1 distance -> L1 distance: 9821.280273\n",
      "  Wasserstein-1 distance -> L2 distance: 38.190632\n",
      "  Wasserstein-1 distance -> Normalized L1: 0.033170\n",
      "  Wasserstein-1 distance -> Normalized L2: 0.071208\n",
      "  Wasserstein-1 distance -> Cosine similarity: 0.501220\n",
      "\n",
      "预测 unknown_env0 与 known_env4 之间的模型距离:\n",
      "  KL(P||Q) -> L1 distance: 7734.552246\n",
      "  KL(P||Q) -> L2 distance: 33.323498\n",
      "  KL(P||Q) -> Normalized L1: 0.027621\n",
      "  KL(P||Q) -> Normalized L2: 0.060178\n",
      "  KL(P||Q) -> Cosine similarity: 0.657766\n",
      "  KL(Q||P) -> L1 distance: 8425.631836\n",
      "  KL(Q||P) -> L2 distance: 33.184216\n",
      "  KL(Q||P) -> Normalized L1: 0.027721\n",
      "  KL(Q||P) -> Normalized L2: 0.061428\n",
      "  KL(Q||P) -> Cosine similarity: 0.688392\n",
      "  Symmetric KL -> L1 distance: 8190.285156\n",
      "  Symmetric KL -> L2 distance: 33.562656\n",
      "  Symmetric KL -> Normalized L1: 0.027853\n",
      "  Symmetric KL -> Normalized L2: 0.062136\n",
      "  Symmetric KL -> Cosine similarity: 0.597637\n",
      "  JS divergence -> L1 distance: 7964.784668\n",
      "  JS divergence -> L2 distance: 33.161793\n",
      "  JS divergence -> Normalized L1: 0.026476\n",
      "  JS divergence -> Normalized L2: 0.060936\n",
      "  JS divergence -> Cosine similarity: 0.679488\n",
      "  Wasserstein-1 distance -> L1 distance: 9712.088867\n",
      "  Wasserstein-1 distance -> L2 distance: 38.115555\n",
      "  Wasserstein-1 distance -> Normalized L1: 0.033429\n",
      "  Wasserstein-1 distance -> Normalized L2: 0.070155\n",
      "  Wasserstein-1 distance -> Cosine similarity: 0.503536\n",
      "\n",
      "预测结果已保存到 /mnt/data/WQ/LoRAT/unknown_env_predictions.json\n",
      "\n",
      "预测结果总结:\n",
      "\n",
      "unknown_env0 与 known_env0 之间的预测模型距离:\n",
      "  基于 KL(P||Q) 的预测:\n",
      "    L1 distance: 9676.680664\n",
      "    L2 distance: 38.781403\n",
      "    Normalized L1: 0.033326\n",
      "    Normalized L2: 0.070953\n",
      "    Cosine similarity: 0.466661\n",
      "  基于 KL(Q||P) 的预测:\n",
      "    L1 distance: 9919.965820\n",
      "    L2 distance: 37.810745\n",
      "    Normalized L1: 0.032522\n",
      "    Normalized L2: 0.068899\n",
      "    Cosine similarity: 0.553067\n",
      "  基于 Symmetric KL 的预测:\n",
      "    L1 distance: 9687.348633\n",
      "    L2 distance: 38.289379\n",
      "    Normalized L1: 0.032758\n",
      "    Normalized L2: 0.070557\n",
      "    Cosine similarity: 0.457882\n",
      "  基于 JS divergence 的预测:\n",
      "    L1 distance: 9701.799805\n",
      "    L2 distance: 38.540901\n",
      "    Normalized L1: 0.033414\n",
      "    Normalized L2: 0.071322\n",
      "    Cosine similarity: 0.472438\n",
      "  基于 Wasserstein-1 distance 的预测:\n",
      "    L1 distance: 9636.652344\n",
      "    L2 distance: 37.905769\n",
      "    Normalized L1: 0.033500\n",
      "    Normalized L2: 0.069498\n",
      "    Cosine similarity: 0.504132\n",
      "\n",
      "unknown_env0 与 known_env1 之间的预测模型距离:\n",
      "  基于 KL(P||Q) 的预测:\n",
      "    L1 distance: 9389.762695\n",
      "    L2 distance: 37.126968\n",
      "    Normalized L1: 0.032173\n",
      "    Normalized L2: 0.067599\n",
      "    Cosine similarity: 0.475518\n",
      "  基于 KL(Q||P) 的预测:\n",
      "    L1 distance: 9091.049805\n",
      "    L2 distance: 36.658718\n",
      "    Normalized L1: 0.030459\n",
      "    Normalized L2: 0.066494\n",
      "    Cosine similarity: 0.496760\n",
      "  基于 Symmetric KL 的预测:\n",
      "    L1 distance: 9009.925781\n",
      "    L2 distance: 37.030174\n",
      "    Normalized L1: 0.031150\n",
      "    Normalized L2: 0.068032\n",
      "    Cosine similarity: 0.466342\n",
      "  基于 JS divergence 的预测:\n",
      "    L1 distance: 9054.257812\n",
      "    L2 distance: 37.012985\n",
      "    Normalized L1: 0.032345\n",
      "    Normalized L2: 0.067938\n",
      "    Cosine similarity: 0.471597\n",
      "  基于 Wasserstein-1 distance 的预测:\n",
      "    L1 distance: 9497.195312\n",
      "    L2 distance: 35.980919\n",
      "    Normalized L1: 0.030357\n",
      "    Normalized L2: 0.061958\n",
      "    Cosine similarity: 0.505163\n",
      "\n",
      "unknown_env0 与 known_env2 之间的预测模型距离:\n",
      "  基于 KL(P||Q) 的预测:\n",
      "    L1 distance: 6336.973633\n",
      "    L2 distance: 22.761778\n",
      "    Normalized L1: 0.019271\n",
      "    Normalized L2: 0.043977\n",
      "    Cosine similarity: 0.621096\n",
      "  基于 KL(Q||P) 的预测:\n",
      "    L1 distance: 7877.602051\n",
      "    L2 distance: 32.017349\n",
      "    Normalized L1: 0.026650\n",
      "    Normalized L2: 0.057191\n",
      "    Cosine similarity: 0.612817\n",
      "  基于 Symmetric KL 的预测:\n",
      "    L1 distance: 5601.561523\n",
      "    L2 distance: 23.303289\n",
      "    Normalized L1: 0.019341\n",
      "    Normalized L2: 0.042075\n",
      "    Cosine similarity: 0.647126\n",
      "  基于 JS divergence 的预测:\n",
      "    L1 distance: 6966.584961\n",
      "    L2 distance: 26.452759\n",
      "    Normalized L1: 0.024200\n",
      "    Normalized L2: 0.047824\n",
      "    Cosine similarity: 0.604647\n",
      "  基于 Wasserstein-1 distance 的预测:\n",
      "    L1 distance: 9292.312500\n",
      "    L2 distance: 34.734791\n",
      "    Normalized L1: 0.030403\n",
      "    Normalized L2: 0.064682\n",
      "    Cosine similarity: 0.492536\n",
      "\n",
      "unknown_env0 与 known_env3 之间的预测模型距离:\n",
      "  基于 KL(P||Q) 的预测:\n",
      "    L1 distance: 9416.111328\n",
      "    L2 distance: 37.254719\n",
      "    Normalized L1: 0.032264\n",
      "    Normalized L2: 0.067652\n",
      "    Cosine similarity: 0.474842\n",
      "  基于 KL(Q||P) 的预测:\n",
      "    L1 distance: 9393.890625\n",
      "    L2 distance: 36.805496\n",
      "    Normalized L1: 0.030861\n",
      "    Normalized L2: 0.066362\n",
      "    Cosine similarity: 0.481910\n",
      "  基于 Symmetric KL 的预测:\n",
      "    L1 distance: 9119.909180\n",
      "    L2 distance: 37.405350\n",
      "    Normalized L1: 0.032017\n",
      "    Normalized L2: 0.069195\n",
      "    Cosine similarity: 0.463236\n",
      "  基于 JS divergence 的预测:\n",
      "    L1 distance: 9196.468750\n",
      "    L2 distance: 37.394691\n",
      "    Normalized L1: 0.032940\n",
      "    Normalized L2: 0.069870\n",
      "    Cosine similarity: 0.472132\n",
      "  基于 Wasserstein-1 distance 的预测:\n",
      "    L1 distance: 9821.280273\n",
      "    L2 distance: 38.190632\n",
      "    Normalized L1: 0.033170\n",
      "    Normalized L2: 0.071208\n",
      "    Cosine similarity: 0.501220\n",
      "\n",
      "unknown_env0 与 known_env4 之间的预测模型距离:\n",
      "  基于 KL(P||Q) 的预测:\n",
      "    L1 distance: 7734.552246\n",
      "    L2 distance: 33.323498\n",
      "    Normalized L1: 0.027621\n",
      "    Normalized L2: 0.060178\n",
      "    Cosine similarity: 0.657766\n",
      "  基于 KL(Q||P) 的预测:\n",
      "    L1 distance: 8425.631836\n",
      "    L2 distance: 33.184216\n",
      "    Normalized L1: 0.027721\n",
      "    Normalized L2: 0.061428\n",
      "    Cosine similarity: 0.688392\n",
      "  基于 Symmetric KL 的预测:\n",
      "    L1 distance: 8190.285156\n",
      "    L2 distance: 33.562656\n",
      "    Normalized L1: 0.027853\n",
      "    Normalized L2: 0.062136\n",
      "    Cosine similarity: 0.597637\n",
      "  基于 JS divergence 的预测:\n",
      "    L1 distance: 7964.784668\n",
      "    L2 distance: 33.161793\n",
      "    Normalized L1: 0.026476\n",
      "    Normalized L2: 0.060936\n",
      "    Cosine similarity: 0.679488\n",
      "  基于 Wasserstein-1 distance 的预测:\n",
      "    L1 distance: 9712.088867\n",
      "    L2 distance: 38.115555\n",
      "    Normalized L1: 0.033429\n",
      "    Normalized L2: 0.070155\n",
      "    Cosine similarity: 0.503536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算unknown_env与known_env之间的分布散度\n",
    "print(\"\\n计算unknown_env与known_env之间的分布散度...\")\n",
    "\n",
    "# 将unknown_env数据转换为幅度并展平\n",
    "unknown_magnitude_data = []\n",
    "for i, env_data in enumerate(unknown_env):\n",
    "    mag_data = complex_to_magnitude(env_data)\n",
    "    flattened_data = mag_data.flatten()\n",
    "    unknown_magnitude_data.append(flattened_data)\n",
    "    print(f\"unknown_env{i} shape: {flattened_data.shape}\")\n",
    "\n",
    "# 计算unknown_env与known_env之间的分布散度\n",
    "unknown_divergences = []\n",
    "for i, unknown_data in enumerate(unknown_magnitude_data):\n",
    "    for j, known_data in enumerate(magnitude_data):\n",
    "        # 确保两个分布具有相同的长度\n",
    "        min_len = min(len(unknown_data), len(known_data))\n",
    "        p = unknown_data[:min_len]\n",
    "        q = known_data[:min_len]\n",
    "        \n",
    "        # 计算各种散度\n",
    "        kl_pq = calculate_kl_divergence(p, q)\n",
    "        kl_qp = calculate_kl_divergence(q, p)\n",
    "        sym_kl = (kl_pq + kl_qp) / 2\n",
    "        js_div = jensenshannon(p/np.sum(p), q/np.sum(q))**2\n",
    "        w_dist = wasserstein_distance(p, q)\n",
    "        \n",
    "        unknown_divergences.append({\n",
    "            'pair': (f'unknown_env{i}', f'known_env{j}'),\n",
    "            'KL(P||Q)': kl_pq,\n",
    "            'KL(Q||P)': kl_qp,\n",
    "            'Symmetric KL': sym_kl,\n",
    "            'JS divergence': js_div,\n",
    "            'Wasserstein-1 distance': w_dist\n",
    "        })\n",
    "        \n",
    "        print(f\"unknown_env{i} 与 known_env{j} 之间的散度:\")\n",
    "        print(f\"  KL(P||Q) = {kl_pq:.6f}\")\n",
    "        print(f\"  KL(Q||P) = {kl_qp:.6f}\")\n",
    "        print(f\"  Symmetric KL = {sym_kl:.6f}\")\n",
    "        print(f\"  JS divergence = {js_div:.6f}\")\n",
    "        print(f\"  Wasserstein-1 distance = {w_dist:.6f}\")\n",
    "        print()\n",
    "\n",
    "# 使用训练好的模型预测unknown_env与known_env之间的模型距离\n",
    "print(\"\\n使用训练好的模型预测unknown_env与known_env之间的模型距离...\")\n",
    "\n",
    "predictions = {}\n",
    "for i, divergence in enumerate(unknown_divergences):\n",
    "    pair = divergence['pair']\n",
    "    print(f\"\\n预测 {pair[0]} 与 {pair[1]} 之间的模型距离:\")\n",
    "    \n",
    "    predictions[pair] = {}\n",
    "    \n",
    "    # 使用每种输入特征进行预测\n",
    "    for input_idx, input_name in enumerate(input_names):\n",
    "        input_value = divergence[input_name]\n",
    "        predictions[pair][input_name] = {}\n",
    "        \n",
    "        # 使用每种输出目标的模型进行预测\n",
    "        for output_idx, output_name in enumerate(output_names):\n",
    "            model_key = f\"{input_name.replace(' ', '_')}_{output_name.replace(' ', '_')}\"\n",
    "            \n",
    "            # 加载模型和缩放器\n",
    "            if model_key in trained_models:\n",
    "                model = trained_models[model_key]\n",
    "                scaler_X, scaler_y = scalers[model_key]\n",
    "                \n",
    "                # 标准化输入\n",
    "                input_scaled = scaler_X.transform([[input_value]])\n",
    "                input_tensor = torch.FloatTensor(input_scaled)\n",
    "                \n",
    "                # 预测\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    prediction_scaled = model(input_tensor)\n",
    "                    # 反标准化\n",
    "                    prediction = scaler_y.inverse_transform(prediction_scaled.numpy())[0, 0]\n",
    "                \n",
    "                predictions[pair][input_name][output_name] = prediction\n",
    "                print(f\"  {input_name} -> {output_name}: {prediction:.6f}\")\n",
    "\n",
    "save_prediction = {}\n",
    "for pair, input_predictions in predictions.items():\n",
    "    save_prediction[str(pair)] = input_predictions\n",
    "\n",
    "# 保存预测结果\n",
    "import json\n",
    "with open('/mnt/data/WQ/LoRAT/unknown_env_predictions.json', 'w') as f:\n",
    "    json.dump(save_prediction, f, indent=2, default=float)\n",
    "\n",
    "print(\"\\n预测结果已保存到 /mnt/data/WQ/LoRAT/unknown_env_predictions.json\")\n",
    "\n",
    "# 总结预测结果\n",
    "print(\"\\n预测结果总结:\")\n",
    "for pair, input_predictions in predictions.items():\n",
    "    print(f\"\\n{pair[0]} 与 {pair[1]} 之间的预测模型距离:\")\n",
    "    for input_name, output_predictions in input_predictions.items():\n",
    "        print(f\"  基于 {input_name} 的预测:\")\n",
    "        for output_name, prediction in output_predictions.items():\n",
    "            print(f\"    {output_name}: {prediction:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "probability_distribution_conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将模型距离转换为概率分布...\n",
      "\n",
      "使用 Symmetric KL 预测 Cosine similarity 来计算概率分布\n",
      "\n",
      "unknown_env0 与各known_env的模型距离:\n",
      "  known_env0: 0.457882\n",
      "  known_env1: 0.466342\n",
      "  known_env2: 0.647126\n",
      "  known_env3: 0.463236\n",
      "  known_env4: 0.597637\n",
      "\n",
      "unknown_env0 与各known_env的相似度概率分布:\n",
      "  Softmax方法:\n",
      "    known_env0: 0.213521\n",
      "    known_env1: 0.211722\n",
      "    known_env2: 0.176706\n",
      "    known_env3: 0.212380\n",
      "    known_env4: 0.185671\n",
      "  高斯核方法:\n",
      "    known_env0: 0.207329\n",
      "    known_env1: 0.206520\n",
      "    known_env2: 0.186746\n",
      "    known_env3: 0.206818\n",
      "    known_env4: 0.192587\n",
      "  反比方法:\n",
      "    known_env0: 0.225022\n",
      "    known_env1: 0.220940\n",
      "    known_env2: 0.159217\n",
      "    known_env3: 0.222421\n",
      "    known_env4: 0.172401\n",
      "\n",
      "概率分布结果已保存到 /mnt/data/WQ/LoRAT/unknown_env_probabilities.json\n",
      "\n",
      "最相似的known_env:\n",
      "\n",
      "unknown_env0 最相似的known_env:\n",
      "  基于Softmax: known_env0 (概率: 0.213521)\n",
      "  基于高斯核: known_env0 (概率: 0.207329)\n",
      "  基于反比: known_env0 (概率: 0.225022)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# 读取预测结果\n",
    "with open('/mnt/data/WQ/LoRAT/unknown_env_predictions.json', 'r') as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "print(\"将模型距离转换为概率分布...\")\n",
    "\n",
    "# 定义softmax函数\n",
    "def softmax(x):\n",
    "    \"\"\"计算softmax值\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))  # 减去最大值以避免数值溢出\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# 定义高斯核函数\n",
    "def gaussian_kernel(x, sigma=1.0):\n",
    "    \"\"\"使用高斯核将距离转换为相似度\"\"\"\n",
    "    return np.exp(-x**2 / (2 * sigma**2))\n",
    "\n",
    "# 将距离转换为概率分布的函数\n",
    "def distance_to_probability(distances, method='softmax'):\n",
    "    \"\"\"\n",
    "    将距离转换为概率分布\n",
    "    method: 'softmax', 'gaussian', 'inverse'\n",
    "    \"\"\"\n",
    "    if method == 'softmax':\n",
    "        # 使用softmax，距离越小概率越大\n",
    "        # 对距离取负值，因为softmax通常用于最大化\n",
    "        return softmax(-np.array(distances))\n",
    "    elif method == 'gaussian':\n",
    "        # 使用高斯核函数\n",
    "        similarities = gaussian_kernel(np.array(distances))\n",
    "        return similarities / np.sum(similarities)\n",
    "    elif method == 'inverse':\n",
    "        # 使用反比函数\n",
    "        # 添加小的epsilon值以避免除零错误\n",
    "        epsilon = 1e-8\n",
    "        inverse_distances = 1.0 / (np.array(distances) + epsilon)\n",
    "        return inverse_distances / np.sum(inverse_distances)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method. Use 'softmax', 'gaussian', or 'inverse'.\")\n",
    "\n",
    "# 对于每个unknown_env，收集与所有known_env的模型距离\n",
    "unknown_env_probabilities = {}\n",
    "\n",
    "# 定义要使用的输入特征和输出目标\n",
    "input_feature = 'Symmetric KL'  # 可以更改为您想要使用的特征\n",
    "output_target = 'Cosine similarity'  # 可以更改为您想要使用的输出目标\n",
    "\n",
    "print(f\"\\n使用 {input_feature} 预测 {output_target} 来计算概率分布\")\n",
    "\n",
    "# 按unknown_env分组收集距离\n",
    "grouped_distances = {}\n",
    "for pair_str, input_predictions in predictions.items():\n",
    "    # 解析pair字符串\n",
    "    pair = eval(pair_str)\n",
    "    unknown_env_name = pair[0]\n",
    "    known_env_name = pair[1]\n",
    "    \n",
    "    # 获取预测的距离\n",
    "    if input_feature in input_predictions and output_target in input_predictions[input_feature]:\n",
    "        distance = input_predictions[input_feature][output_target]\n",
    "        \n",
    "        # 按unknown_env分组\n",
    "        if unknown_env_name not in grouped_distances:\n",
    "            grouped_distances[unknown_env_name] = []\n",
    "        grouped_distances[unknown_env_name].append((known_env_name, distance))\n",
    "\n",
    "# 对每个unknown_env计算概率分布\n",
    "for unknown_env_name, distances in grouped_distances.items():\n",
    "    print(f\"\\n{unknown_env_name} 与各known_env的模型距离:\")\n",
    "    \n",
    "    # 提取距离值\n",
    "    distance_values = [dist[1] for dist in distances]\n",
    "    known_env_names = [dist[0] for dist in distances]\n",
    "    \n",
    "    # 显示距离\n",
    "    for i, (known_env, dist) in enumerate(distances):\n",
    "        print(f\"  {known_env}: {dist:.6f}\")\n",
    "    \n",
    "    # 使用不同方法计算概率分布\n",
    "    softmax_probs = distance_to_probability(distance_values, method='softmax')\n",
    "    gaussian_probs = distance_to_probability(distance_values, method='gaussian')\n",
    "    inverse_probs = distance_to_probability(distance_values, method='inverse')\n",
    "    \n",
    "    # 保存结果\n",
    "    unknown_env_probabilities[unknown_env_name] = {\n",
    "        'known_envs': known_env_names,\n",
    "        'distances': distance_values,\n",
    "        'softmax_probabilities': softmax_probs.tolist(),\n",
    "        'gaussian_probabilities': gaussian_probs.tolist(),\n",
    "        'inverse_probabilities': inverse_probs.tolist()\n",
    "    }\n",
    "    \n",
    "    # 显示概率分布\n",
    "    print(f\"\\n{unknown_env_name} 与各known_env的相似度概率分布:\")\n",
    "    print(\"  Softmax方法:\")\n",
    "    for i, (known_env, prob) in enumerate(zip(known_env_names, softmax_probs)):\n",
    "        print(f\"    {known_env}: {prob:.6f}\")\n",
    "    \n",
    "    print(\"  高斯核方法:\")\n",
    "    for i, (known_env, prob) in enumerate(zip(known_env_names, gaussian_probs)):\n",
    "        print(f\"    {known_env}: {prob:.6f}\")\n",
    "        \n",
    "    print(\"  反比方法:\")\n",
    "    for i, (known_env, prob) in enumerate(zip(known_env_names, inverse_probs)):\n",
    "        print(f\"    {known_env}: {prob:.6f}\")\n",
    "\n",
    "# 保存概率分布结果\n",
    "with open('/mnt/data/WQ/LoRAT/unknown_env_probabilities.json', 'w') as f:\n",
    "    json.dump(unknown_env_probabilities, f, indent=2)\n",
    "\n",
    "print(\"\\n概率分布结果已保存到 /mnt/data/WQ/LoRAT/unknown_env_probabilities.json\")\n",
    "\n",
    "# 找到每个unknown_env最相似的known_env\n",
    "print(\"\\n最相似的known_env:\")\n",
    "for unknown_env_name, probs in unknown_env_probabilities.items():\n",
    "    known_envs = probs['known_envs']\n",
    "    softmax_probs = np.array(probs['softmax_probabilities'])\n",
    "    gaussian_probs = np.array(probs['gaussian_probabilities'])\n",
    "    inverse_probs = np.array(probs['inverse_probabilities'])\n",
    "    \n",
    "    # 找到最大概率的索引\n",
    "    softmax_max_idx = np.argmax(softmax_probs)\n",
    "    gaussian_max_idx = np.argmax(gaussian_probs)\n",
    "    inverse_max_idx = np.argmax(inverse_probs)\n",
    "    \n",
    "    print(f\"\\n{unknown_env_name} 最相似的known_env:\")\n",
    "    print(f\"  基于Softmax: {known_envs[softmax_max_idx]} (概率: {softmax_probs[softmax_max_idx]:.6f})\")\n",
    "    print(f\"  基于高斯核: {known_envs[gaussian_max_idx]} (概率: {gaussian_probs[gaussian_max_idx]:.6f})\")\n",
    "    print(f\"  基于反比: {known_envs[inverse_max_idx]} (概率: {inverse_probs[inverse_max_idx]:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "model_aggregation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用softmax概率分布作为系数聚合模型...\n",
      "\n",
      "为 unknown_env0 聚合模型...\n",
      "  使用的聚合系数 (softmax概率):\n",
      "    known_env0: 0.213834\n",
      "    known_env1: 0.209452\n",
      "    known_env2: 0.171295\n",
      "    known_env3: 0.212712\n",
      "    known_env4: 0.192707\n",
      "  聚合模型已保存到: /mnt/data/WQ/LoRAT/mapping_model/aggregated_model_Symmetric_Cosine.pt\n",
      "\n",
      "所有模型聚合完成!\n",
      "\n",
      "验证聚合模型...\n",
      "\n",
      "unknown_env0 的聚合模型参数:\n",
      "  spatial_block.blocks.0.s_attn.w_q.lora_A_r: shape torch.Size([8, 128]), mean 0.001781, std 0.050632\n",
      "  spatial_block.blocks.0.s_attn.w_q.lora_B_r: shape torch.Size([128, 8]), mean 0.000000, std 0.000000\n",
      "  spatial_block.blocks.0.s_attn.w_q.lora_A_i: shape torch.Size([8, 128]), mean 0.001954, std 0.050310\n",
      "  ... (共288个参数)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"\\n使用softmax概率分布作为系数聚合模型...\")\n",
    "\n",
    "# 读取概率分布结果\n",
    "with open('/mnt/data/WQ/LoRAT/unknown_env_probabilities.json', 'r') as f:\n",
    "    unknown_env_probabilities = json.load(f)\n",
    "\n",
    "# 为每个unknown_env聚合模型\n",
    "aggregated_models = {}\n",
    "\n",
    "for unknown_env_name, probs in unknown_env_probabilities.items():\n",
    "    print(f\"\\n为 {unknown_env_name} 聚合模型...\")\n",
    "    \n",
    "    # 获取softmax概率\n",
    "    softmax_probs = np.array(probs['softmax_probabilities'])\n",
    "    known_env_names = probs['known_envs']\n",
    "    \n",
    "    print(f\"  使用的聚合系数 (softmax概率):\")\n",
    "    for i, (known_env, prob) in enumerate(zip(known_env_names, softmax_probs)):\n",
    "        print(f\"    {known_env}: {prob:.6f}\")\n",
    "    \n",
    "    # 将known_env名称转换为索引\n",
    "    # known_env0, known_env1, known_env2, known_env3, known_env4 对应索引 0, 1, 2, 3, 4\n",
    "    known_env_indices = []\n",
    "    for known_env in known_env_names:\n",
    "        # 从名称中提取索引\n",
    "        idx = int(known_env.replace('known_env', ''))\n",
    "        known_env_indices.append(idx)\n",
    "    \n",
    "    # 获取对应的模型\n",
    "    models_to_aggregate = [known_models[i] for i in known_env_indices]\n",
    "    \n",
    "    # 创建聚合模型\n",
    "    aggregated_model = {}\n",
    "    \n",
    "    # 获取第一个模型的键作为参考\n",
    "    reference_model = models_to_aggregate[0]\n",
    "    \n",
    "    # 对每个参数进行加权平均\n",
    "    for key in reference_model.keys():\n",
    "        # 初始化聚合参数\n",
    "        aggregated_param = torch.zeros_like(reference_model[key])\n",
    "        \n",
    "        # 对所有模型的参数进行加权平均\n",
    "        for i, model in enumerate(models_to_aggregate):\n",
    "            weight = softmax_probs[i]\n",
    "            aggregated_param += weight * model[key]\n",
    "        \n",
    "        # 保存聚合后的参数\n",
    "        aggregated_model[key] = aggregated_param\n",
    "    \n",
    "    # 保存聚合模型\n",
    "    aggregated_models[unknown_env_name] = aggregated_model\n",
    "    \n",
    "    distance_name = input_feature.split(' ')[0] + '_' + output_target.split(' ')[0]\n",
    "    # 保存到文件\n",
    "    save_path = f'/mnt/data/WQ/LoRAT/mapping_model/aggregated_model_{distance_name}.pt'\n",
    "    torch.save(aggregated_model, save_path)\n",
    "    print(f\"  聚合模型已保存到: {save_path}\")\n",
    "\n",
    "print(\"\\n所有模型聚合完成!\")\n",
    "\n",
    "# 验证聚合模型\n",
    "print(\"\\n验证聚合模型...\")\n",
    "for unknown_env_name, aggregated_model in aggregated_models.items():\n",
    "    print(f\"\\n{unknown_env_name} 的聚合模型参数:\")\n",
    "    for key, param in list(aggregated_model.items())[:3]:  # 只显示前3个参数\n",
    "        print(f\"  {key}: shape {param.shape}, mean {param.mean().item():.6f}, std {param.std().item():.6f}\")\n",
    "    if len(aggregated_model) > 3:\n",
    "        print(f\"  ... (共{len(aggregated_model)}个参数)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
